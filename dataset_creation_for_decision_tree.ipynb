{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGST0V7abl6oS688cY03Pv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mike-jansen/misinformation-analysis-capstone/blob/main/dataset_creation_for_decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZozMy56UJjT",
        "outputId": "7cba8e18-95fb-4688-c727-374905e411c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "UMlSetu6dSzP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqUu-6ThUDit"
      },
      "outputs": [],
      "source": [
        "# loading data\n",
        "path = '/content/drive/MyDrive/output/'\n",
        "liar_false = pd.read_csv(path + 'liar_false.csv')\n",
        "liar_true = pd.read_csv(path + 'liar_true.csv')\n",
        "nela_false = pd.read_csv(path + 'nela_false.csv')\n",
        "nela_true = pd.read_csv(path + 'nela_true.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nela_true.rename(columns={'content': 'text'}, inplace=True)\n",
        "nela_false.rename(columns={'content': 'text'}, inplace=True)"
      ],
      "metadata": {
        "id": "TUMKjzkQZJkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar_false = liar_false.head(10000)\n",
        "liar_true = liar_true = liar_false.head(10000)\n",
        "nela_false = nela_false.head(10000)\n",
        "nela_true = nela_true.head(10000)"
      ],
      "metadata": {
        "id": "X0Ob9dSyckQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the dataset"
      ],
      "metadata": {
        "id": "_o5Gll0YdZ4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install NRCLex\n",
        "from nrclex import NRCLex\n",
        "# import the punkt tokenizer for NRCLex to work\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from collections import defaultdict\n",
        "import json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZpzVWW5Uwmh",
        "outputId": "51633ce0-6e5c-4ee1-8cd8-6d144ebc0bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting NRCLex\n",
            "  Downloading NRCLex-4.0-py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from NRCLex) (0.17.1)\n",
            "INFO: pip is looking at multiple versions of nrclex to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading NRCLex-3.0.0.tar.gz (396 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob->NRCLex) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (4.65.0)\n",
            "Building wheels for collected packages: NRCLex\n",
            "  Building wheel for NRCLex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NRCLex: filename=NRCLex-3.0.0-py3-none-any.whl size=43308 sha256=f867dfee6b0450622c8866af41e53498f20b043f0dccc5b6a17c606436c77b0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/10/44/6abfb1234298806a145fd6bcaec8cbc712e88dd1cd6cb242fa\n",
            "Successfully built NRCLex\n",
            "Installing collected packages: NRCLex\n",
            "Successfully installed NRCLex-3.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function that calculates the NRCLex scores for a piece of text\n",
        "def calculate_nrc_scores(text):\n",
        "  if isinstance(text, str):\n",
        "    lex = NRCLex(text)\n",
        "    return lex.affect_frequencies"
      ],
      "metadata": {
        "id": "fnWGMYi1Yq6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = [liar_false, liar_true, nela_false, nela_true]\n",
        "updated_dataframes = []\n",
        "\n",
        "# append the NRCLex scores to original datasets\n",
        "for df in dataframes:\n",
        "    all_scores = df['text'].apply(calculate_nrc_scores)\n",
        "    all_scores = all_scores.apply(lambda x: {} if x is None else x)  # Replace None values with {}\n",
        "    df_new = pd.DataFrame(all_scores.tolist())\n",
        "    updated_df = pd.concat([df, df_new], axis=1)\n",
        "    updated_dataframes.append(updated_df)"
      ],
      "metadata": {
        "id": "zpL07x6dY0AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar_false = updated_dataframes[0]\n",
        "liar_true = updated_dataframes[1]\n",
        "nela_false = updated_dataframes[2]\n",
        "nela_true = updated_dataframes[3]"
      ],
      "metadata": {
        "id": "o_xUiYqLegTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export the new dataframes, then use the new features in the decision tree\n",
        "import os\n",
        "output_dir = '/content/drive/MyDrive/output'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "liar_false.to_csv(os.path.join(output_dir, 'liar_false.csv'), index=False)\n",
        "liar_true.to_csv(os.path.join(output_dir, 'liar_true.csv'), index=False)\n",
        "nela_false.to_csv(os.path.join(output_dir, 'nela_false.csv'), index=False)\n",
        "nela_true.to_csv(os.path.join(output_dir, 'nela_true.csv'), index=False)"
      ],
      "metadata": {
        "id": "mPcCHu38tPCR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}